<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My Portfolio</title>
    <link rel="stylesheet" href="style.css">

</head>
<body>

    <div class="title">MY PORTFOLIO</div>

    <div class="section">
        <div class="section-title green">Session 1: Juxtaposition Map</div>
        <div class="content">
            <iframe src='https://flo.uri.sh/visualisation/21117435/embed' title='Interactive or visual content' class='flourish-embed-iframe' frameborder='0' scrolling='no' style='width:100%;height:600px;' sandbox='allow-same-origin allow-forms allow-scripts allow-downloads allow-popups allow-popups-to-escape-sandbox allow-top-navigation-by-user-activation'></iframe><div style='width:100%!;margin-top:4px!important;text-align:right!important;'><a class='flourish-credit' href='https://public.flourish.studio/visualisation/21117435/?utm_source=embed&utm_campaign=visualisation/21117435' target='_top' style='text-decoration:none!important'><img alt='Made with Flourish' src='https://public.flourish.studio/resources/made_with_flourish.svg' style='width:105px!important;height:16px!important;border:none!important;margin:0!important;'> </a></div>
             <p class="paragraph"><strong>Critical commentary: </strong>This juxtaposition map explores whether countries with lower economic development tend to have higher fertility rates. According to Solnit (2010), maps are “a selection of relevant data that arises from relevant desires and questions”. By using data from 2021, this map investigates the link between GDP per capita and fertility rates, while also considering other factors like public spending on education and the amount of maternity leave offered. This combination of variables shows how economic and policy factors can work together to affect fertility rates. To make it easier to explore, I used a points map with filters that let viewers interact and look at country-specific data, comparing different factors, this approach aligns with Crampton’s (2010) concept of mashups, which refers to a website or web-based tool that merges multiple sources of content into a customized experience. By juxtaposing economic indicators and social policies, the map challenges the idea that fertility rates are determined solely by economic factors. Notable examples are South Korea, where high GDP and strong welfare policies result in a low fertility rate, and Nigeria, where lower GDP, less welfare, and higher fertility rates are found. However, as Solnit (2010) points out, maps simplify the complexities of real-life situations. For example, Nigeria’s high fertility rate is shaped by cultural values, religious beliefs, and insufficient family planning funding (Emeka, 2024), demonstrating that data alone cannot fully explain such complex issues. Similarly, ethical considerations are crucial when handling data in this context. D’Ignazio and Klein (2020) notes that data and algorithms are shaped by cultural and personal biases, which can lead to a false sense of objectivity. Recognizing these limitations, and to ensure the reliability of the data while minimizing bias, I selected authoritative sources such as Our World in Data, the IMF, and the World Bank Group. This map avoids presenting a singular “truth” and instead encourages critical engagement with the data.</p>
            <p class="paragraph"><strong>Crampton, J. W. (2010). <i> Mapping: a critical introduction to cartography and GIS. </i>Wiley-Blackwell.</strong></p>
            <p class="paragraph"><strong>D’Ignazio, C. and Klein, L. (2020) '2. Collect, Analyze, Imagine, Teach', in <i> Data Feminism. </i>Available at: https://data-feminism.mitpress.mit.edu/pub/ei7cogfn/release/4 </strong></p>
            <p class="paragraph"><strong>Emeka, G. (2024). <i> Nigeria faces surging population amid lagging family services. </i>Voice of America. Available at: https://www.voanews.com/a/nigeria-faces-surging-population-amid-lagging-family-services/7695677.html</strong></p>
            <p class="paragraph"><strong>Solnit, R. (2010). <i> Infinite city: a San Francisco atlas. </i>University of California Press.</strong></p>
        </div>
    </div>



    <div class="section">
        <div class="section-title blue">Session 2: Interactive Documentary</div>
        <div class="content">
            <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
                <iframe
                  src="https://player.stornaway.io/embed/f3856ecf"
                  frameborder="0"
                  allowfullscreen
                  allow="accelerometer; gyroscope;autoplay;"
                  style="width: 100%; height: 100%; position: absolute; top: 0; left: 0;"></iframe>
                <script src="https://studio.stornaway.io/embed/v1/standalone_player.js" defer></script>
              </div>
            <p class="paragraph"><strong>Critical commentary: </strong>This interactive documentary focuses on how people from different cultures view animals and how these views affect the way animals are represented. By exploring animals like black cats, dragons, and weasels through myths, history, and cultural traditions, the project shows how human ideas can give animals both positive and negative meanings. For example, black cats are often linked to bad luck because of superstitions, which has sadly led to them having the lowest adoption rates and highest euthanasia rates in shelters (Trasser, 2024). This example demonstrates how human beliefs can directly impact animal welfare. I chose this topic because I wanted to explore how the meanings we attach to animals are shaped by human stories and how these stories affect animals in the real world. Using a non-linear and branching structure lets viewers explore the stories of each animal individually while also seeing the bigger picture of how cultures and histories connect. Nash (2017) explains that interactive documentaries allow viewers to be more involved, helping them build their understanding of the subject rather than just watching passively. This approach makes the documentary more engaging and reflective, encouraging audiences to think about the bigger themes. The documentary mainly follows the expository mode, bringing together images, videos, and text from different times and places to make an argument about how people shape the meanings of animals (Nicholes & Baron, 2024). At the same time, it includes poetic elements by presenting animals in new ways that encourage viewers to think differently about their familiar symbols (Nicholes & Baron, 2024). Ethical concerns were also important during the project, especially when using media from online sources, as privacy and access can be sensitive issues (Rose, 2017). By respecting these considerations, this documentary aims not only to share information but also to encourage critical thinking about how our cultural beliefs shape our relationships with animals and nature.</p>
            <p class="paragraph"><strong>Nash, K. 2017. 1. I-docs and the documentary tradition: exploring questions of engagement. In: Aston, J., Gaudenzi, S. and Rose, M. ed. <i>I-Docs: The Evolving Practices of Interactive Documentary. </i>New York Chichester, West Sussex: Columbia University Press, pp. 9-25.</strong></p>
            <p class="paragraph"><strong>Nichols, B. & Baron, J. (2024) Introduction to documentary. Fourth edition.</strong></p>
            <p class="paragraph"><strong>Rose, G. (2017) Gillian Rose discusses visual methods.</strong></p>
            <p class="paragraph"><strong>Trasser, S. (2024).<i>The Power of Black Cats: Legends That Haunt Them, Responsible Adoptions. </i>[online] www.msj.edu. Available at: https://www.msj.edu/news/2024/02/the-power-of-black-cats.html</strong></p>
        
        </div>
    </div>

    <div class="section">
        <div class="section-title red">Session 3: Machine Learning</div>
        <div class="content">
            <p class="paragraph"><strong>A.	Research Question:</strong></p>
            <p class="paragraph">How do gender biases manifest in AI-generated images of specific professions?</p>
            <p class="paragraph"><strong>B.	Underlying data:</strong></p>
            <p class="paragraph">Data from DATAUSA (2022), sourced from the U.S. Census Bureau ACS PUMS 5-Year Estimates, https://datausa.io/</p>
            <p class="paragraph"><strong>C.	Description of the process:</strong></p>
            <p class="paragraph">1) I selected three professions to analyse gender representation in AI-generated images:</p>
            <ul>
                <li>Preschool Teacher</li>
                <li>Bricklayer</li>
                <li>Bartender</li>
            </ul>
            <p class="paragraph">2) I used Canva’s AI creation tool to generate images for each profession. For each profession, I used three different prompts (each prompt generated 8 images):</p>
            <ul>
                <li>A gender-neutral prompt for the profession</li>
                <li>A prompt emphasizing male representation</li>
                <li>A prompt emphasizing female representation</li>
            </ul>
            <p class="paragraph">3) I analysed the AI-generated images to determine gender representation for each profession. I then compared these results against real-world data from DATAUSA (2022), which provides the gender breakdown for these professions in the U.S.</p>
            <img src="https://github.com/reneew23/reneew23.github.io/blob/main/Real%20Data%20vs%20AI%20image.png?raw=true" alt="AI Image 3"> 
            <p class="paragraph"><strong>D. Screenshots of tests</strong></p>
            <p class="paragraph">On the left is the text prompt I entered into Canva’s AI creation tool, and on the right is the corresponding image generated based on that prompt. These screenshots document the testing process for gender-neutral, female, and male prompts across all three professions:</p> 
            <img src="https://github.com/reneew23/reneew23.github.io/blob/main/Preschool.png?raw=true" alt="Preschool">
            <img src="https://github.com/reneew23/reneew23.github.io/blob/main/Preschool%20Female.png?raw=true" alt="Preschool Female">
            <img src="https://github.com/reneew23/reneew23.github.io/blob/main/Preschool%20Male.png?raw=true" alt="Preschool Male">
            <img src="https://github.com/reneew23/reneew23.github.io/blob/main/Bricklayer.png?raw=true" alt="Bricklayer">
            <img src="https://github.com/reneew23/reneew23.github.io/blob/main/Bricklayer%20Female.png?raw=true" alt="Bricklayer Female">
            <img src="https://github.com/reneew23/reneew23.github.io/blob/main/Bricklayer%20Male.png?raw=true" alt="Bricklayer Male">
            <img src="https://github.com/reneew23/reneew23.github.io/blob/main/Bartender.png?raw=true" alt="Bartender">
            <img src="https://github.com/reneew23/reneew23.github.io/blob/main/Bartender%20Female.png?raw=true" alt="Bartender Female">
            <img src="https://github.com/reneew23/reneew23.github.io/blob/main/Bartender%20Male.png?raw=true" alt="Bartender Male">
            <p class="paragraph"><strong>Critical commentary: </strong>In this part, I aim to explore whether AI-generated images show gender bias when creating pictures of people in different jobs. Although I worked with a small dataset, the results clearly show that AI systems have built-in gender biases. For example, when I specifically asked the AI to generate images of a certain gender, it successfully created pictures that matched my request. However, when I used neutral prompts without mentioning gender, the AI often created images based on common stereotypes, reflecting biases found in society. I chose to examine three professions: preschool teachers (mostly women in real life), bricklayers (mostly men), and bartenders (a job with a more even mix of genders). For the first two professions, the AI-generated images closely matched real-world data, suggesting that the model relies heavily on patterns in its training data. However, the results for bartenders revealed an unexpected bias. Despite the occupation being slightly more female-dominated, the AI predominantly generated male bartender images when no gender was specified in the prompt. This disparity highlights the AI's tendency to default to male representation in roles perceived as neutral or ambiguous. In addition to gender biases, unexpected patterns related to race appeared in the AI-generated images. For preschool teachers, 18 images showed people of color, but very few included Asians. For bricklayers, only five images featured people of color, and none showed Asians. Interestingly, the bartender images had a more balanced mix of races. These results could be because the AI was trained on data that reflects real-world power structures and cultural ideas. As Crawford (2021) points out, AI systems are not neutral or separate from society—they are built using past systems and ideas, which often repeat existing social inequalities. Furthermore, the tendency of AI systems to perpetuate biases is compounded by their design. The AI operates on data-driven decisions (Kirk, 2019) and is ultimately shaped by the priorities embedded in its creation process. As Bianchi et al. (2023) warn, the widespread availability of these technologies raises significant concerns about their influence on society. My findings emphasize that AI systems, while powerful, are limited by the biases encoded in their training data. They serve as a registry of power (Crawford, 2021), reflecting existing societal inequalities rather than challenging them.</p>
            <p class="paragraph"><strong>Bianchi, F. et al. (2023) ‘Easily accessible text-to-image generation amplifies demographic stereotypes at large scale’, <i>2023 ACM Conference on Fairness, Accountability, and Transparency, </i>pp. 1493–1504. </strong></p>
            <p class="paragraph"><strong>Crawford, K (2021), The Atlas of AI : Power, Politics, and the Planetary Costs of Artificial Intelligence, Yale University Press, New Haven. Available from: ProQuest Ebook Central.</strong></p>
            <p class="paragraph"><strong>Kirk, A. (2019). Data visualisation: A handbook for data driven design.</strong></p>


            <div class="yellow">THE END</div>
    </div>
    </body>
    </html>
    
    
